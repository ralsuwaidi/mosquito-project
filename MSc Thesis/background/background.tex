
\chapter{Background Theory}
\label{ch:background}

\section{Introduction to Literature Review}
Many arthropods are vectors for diseases `like malaria, dengue, yellow fever, filariasis, leishmaniasis and Chagas disease'\cite{angarita2016novel}. These insects are known to spend the majority of their time in close proximity to humans, blood-feeding on them and their domesticated animals. Limited knowledge is available in mosquito feeding behaviour during host interaction. This information is usually generalised into end points like  `locations and times of entering, arrival at the host, resting or exiting.'\cite{angarita2016novel}. If the characteristics of mosquito flight is better understood then a feasible design of an intervention system can be made.

Virtual Reality has been studied and used in a variety of scientific fields ranging from training in laparoscopic surgery \cite{gurusamy2009virtual} to smart city simulation \cite{lv2016virtual}. It holds promise in communication design intent and simulating virtual environments that are usually inaccessible or too dangerous. The last twenty years immensely helped mature the virtual reality field and much research has been done in that aspect \cite{steuer1992defining}. 

Using virtual reality to study mosquito host interaction may be crucial to understand mosquito flight behaviour. Due to the virtual nature of the project it is possible to project the virtual environment as if the user is the mosquito. To be able to study mosquito behaviour in this new dimension, with accurate data of time and space, may give rise to a deeper understanding in mosquito behaviour and could prove a valuable link to understanding mosquito visual systems and blood feeding pattern.

My supervisor professor David Towers, a member of the Institute of Physics and a Chartered Physicist, and his team have successfully gathered flight data of malaria carrying vectors for field research. The data consists of snapshot of the mosquito's location, in x,y and z dimensions, relative to time and due to the nature of the data a two dimensional display might not be optimal. Hence, this project aims to use Virtual reality, which shows promise in the scientific visualisation fields, as a platform to display the mosquito behaviour with respect to time. 



\section{Aims and Objectives}
\begin{itemize}
    \item To display in a virtual environment a flight path of a mosquito, or set of mosquitoes, which changes with time. The input data is in four dimensional (4D) variables which are (x,y,z,t).
    \item To provide a mean to choose between the different flight tracks and to cycle between mosquito view and observer view (and maybe host view).
    \item To be able to choose a specific time and show the mosquito data at that moment.
    \item (if possible) To use physics in the virtual environment, like gravity, acceleration and inertia, to make the mosquito flight smoother and more natural instead of straight flight paths with constant velocity.
    \item A human model should be available inside a model of a bednet for each data set.
\end{itemize}

The final project should deliver a mean to display a mosquito flight track over a period of time in a virtual environment. Optimally, several mosquito track paths could be layered on top of each other with a way to choose a specific path while keeping the others hidden. Hence, an interactive element should be developed to make it possible to select specific data tracks to display with the additional possibility of selecting a given time for said track.

The project should make it possible to shift between ``observer view'' and ``mosquito view'' where the observer view is the display of the virtual environment in the perspective of an outside observer looking at the mosquito as it flies in front of them. The mosquito view should be in the perspective of the mosquito as it flies. Additionally, the mosquito view should be able to orient itself to face the direction of motion as it passes each point. An interesting  design idea is to also have a ``host view'' as well which is the virtual environment in the perspective of the host as he is lying down. 

The mosquito trail should be displayed as either the entire track greyed out with the instantaneous mosquito visible in a different colour, or in a recent trail which lingers a few seconds behind the mosquito. The former could be advantageous when studying a single track however with multiple tracks it may be beneficial to use the latter instead due to overlapping of tracks. 

An improvement could be to add an overlay of data while in either observer or mosquito views. For example, when in mosquito view data like velocity, Euler angles, acceleration and distance from host could be displayed in a section of the view. This could be done by attaching the overlay to the camera so that as the user rotates his head the overlay would be visible at the corner at all times. However it should be made such as it is far enough from the centre of view as to not obstruct the line of sight but clear enough to be read at any moment. The overlay could also be present when in observer view but it could be static in this case since the observer camera is not changing positions. The observer overlay could be present either with a click of a button or present at all times depending on which is more convenient and comfortable.



\section{Mosquito Literature Review}

\subsection{Mosquito Species}

Mosquito carry diseases depending on the species. The primary malaria carrier is a species known as \textit{anopheles gambiae} (another minor malaria vector is a species known as \textit{Culex quinquefasciatus}) and it is mostly active at night . Hence, a bed-net is a useful tool for malaria prevention. Another common disease vector is a mosquito species known as \textit{aedes aegypti} which is responsible the Zika virus, Chikungunya and dengue fever. The \textit{aedes aegypti} is mostly active in the day therefore bed-nets are not applicable in this case.

Table \ref{mosqSpecies} is gathered from \cite{juliano2005ecology} and documents the more common mosquito species and the associated diseases. 
\begin{landscape}
\bgroup
\def\arraystretch{1.5}
\begin{table}[ht]
\centering
\caption{Human and animal disease outbreaks associated with invasive mosquitoes}
\label{mosqSpecies}
\begin{tabular}{@{}llllll@{}}
\toprule
Disease                & Invasive Mosquitoes       & Locations     & Dates of epidemics & Source of pathogen           & Reference \\ \midrule
Yellow Fever           & \textit{Aedes aegypti}             & Americas      & 16-20th centuries  & Introduced with the mosquito &           \\
Dengue                 & \textit{Aedes aegypti}             & Americas      & 17-20th centuries  & Introduced with the mosquito &           \\
Dengue                 & \textit{Aedes aegypti}             & Asia          & 19-20th centuries  & Native                       &           \\
Dengue                 & \textit{Aedes albopictus}          & Hawaii        & 2001               & Introduced with the mosquito &           \\
West Nile encephalitis & \textit{Culex pipiens}\footnote{Species of the \textit{C. pipiens} complex}             & North America & 1999-present       & Introduced with the mosquito &           \\
Avian malaria          & \textit{Culex quinquefasciatus}\footnote{Only includes the anthropophilic species of the complex, Anopheles gambiae s.s. and Anopheles arabiensis.}    & Hawaii        & 20th century       & Introduced with the mosquito &           \\
Human malaria          & \textit{Anopheles gambiae complex} & Brazil        & 1930-1940          & Native                       &           \\
Human malaria          & \textit{Anopheles gambiae complex} & Mauritius     & 1866-67            & Introduced with the mosquito &           \\
Human malaria          & \textit{Anopheles darlingi}        & Peru          & 1992-1999          & Native                       &           \\ \bottomrule
\end{tabular}
\end{table}
\egroup
\end{landscape}

\subsection{Sensitivity to Carbon Dioxide and Vertebrate Odour}
Male mosquito's attraction to female mosquito's pheromones has been well documented, however, little research has been made regarding the methodology of locating a blood meal using odours emitted by the host. Pheromones are relatively simple messages usually in a specific ratio of components which contain mate recognition information as well as orientation. Moths respond to this message, even as brief as 10ms by surging upwards\cite{mafra1994}, and they are also able to differentiate between a pheromone and antagonists (component of pheromone made by other species which reduces attraction) within as little as 1 ms \cite{baker1998moth}.
\subsubsection{Interaction with host odour}
Mosquito's, however, interact in a very different to odours emanating from the host. Host odours contain a complex mixture of compounds\cite{bowen1996sensory} and different sensory neurons are required. Mosquito's pick up ambiguous ques as \lq many odours are not specific to a vertebrate host\rq\cite{Dekker2963}. These remain present in empty houses, and vary from species to species and even to individuals in the same species \cite{bernier2001chemical}. Finding out the odour or mixture of odours are paramount for host recognition by mosquitoes.

In contrast, CO$_2$ exhaled from the host is a universal attractor \cite{reeves1953}. Fluctuating levels of diluted CO$_2$ (atmospheric around 0.035\% and exhaled around 4\%) serves as a strong indicator that signifies the proximity of a living host. The influence of CO$_2$ to mosquitoes has been tested and on top of being a strong activator and attractant, CO$_2$ \lq can influence the mosquito's olfactory response to skin odours, thereby acting as a ``releasing stimulus"\rq\cite{Dekker2963}. 

Dekker et al. in the paper ``Carbon dioxide instantly sentizes female yellow fever mosquitoes to human skin odours" observed the effect of adding CO$_2$ and human odours of different concentrations to the behaviour of a couple of female yellow fever mosquitoes. The data from their experiment shows that the for the mosquito species \textit{Ae. aegypti} \lq appeared several orders of magnitude more sensitive to dilutions of human-emitted levels of CO$_2$ than to dilutions of skin odours, as reflected in activation, orientation and source finding.\rq\cite{Dekker2963}. The human odour seems to activate the mosquitoes only when the mosquitoes are very close to the human host. However, unlike moths which increase their speed by twofolds \cite{stelin2004}, mosquito flight speed remained relatively constant in or outside the plume. This may be attributed to the reduction of flight stability if the mosquito increases its speed by a significant margin \cite{lehmann2001production}. The results for the track angle showed that the \textit{Ae. aegypti} rapidly responds to entering the odour plume \lq within 200 $ms$\rq\cite{Dekker2963}. This is also consistent with the findings in \cite{vickers2000mechanisms} where the response time is the same and the track angle changed upwind of the odour plume. Change in track angle towards the upwind odour plume has been recorded in \cite{brady1989odour, paynter1993flight, schofield1997effects} in response to CO$_2$. The same flight pattern has been recorded in \cite{Dekker2963} when the mosquito is in the odour plume, however, \lq exiting the plume resulted in a similarly rapid increase to more due crosswind\rq. The track angle response of the \textit{Ae. aegypti} in an odour plume with at 1\% CO$_2$ concentration slightly differs.  The mosquitoes, when exiting the plume, change their angle more slowly than in lower CO$_2$ concentrations. A reason might be due to the mosquitoes' sensory response adapting quickly when stimulated \cite{grant1996electrophysiological}.
\subsubsection{Degree of sensitivity towards CO$_2$ and vertibrate odour}
Findings in \cite{Dekker2963} seem to suggest that the mosquito \textit{Ae. aegypti} is less sensitive to human odour than previously thought in \cite{gillies1980role, takken1999odor}.  Using source finding to indicate the ``attractiveness'' of the odour, it is clear that \textit{Ae. aegypti} mosquitoes are more attracted and are more sensitive to CO$_2$ than to human odour \cite{Dekker2963}. The mosquitoes lose sensitivity rapidly the more diluted the skin odour mix is in contrast to the dilution of CO$_2$ where the mosquitoes still responded even at highly diluted mixtures. Other factors such as wind direction and the stability of the atmosphere may also limit the odour plume's behaviour to a vertebrate host \cite{brady1989odour, murlis1992odor}. 

\subsection{3D Flight Behaviour of a Disease Vector}

Host seeking behaviour of a mosquito in an odour plume can be imagined as a path towards the source of the odour. In a natural environment, the odour plume is not a `cone shape cloud with straight edges. In a natural windy situation, an odour plume is highly heterogeneous'\cite{beeuwkes20083} due to diffusion. The turbulent nature of the wind makes it difficult to indicate the source of the odour hence the instantaneous wind direction, by itself, is not very reliable \cite{brady1989odour}.  Dilution is affected by the wind speed and direction of the wind which influences the overall shape of the plume. It can be assumed that the gaps of clean air will expand the further the plume is from the source \cite{murlis1992odor}. In order for the mosquito to find the odour source it must first orient itself. \cite{kennedy1939behaviour} recorded that the mosquito \textit{Ae. aegypti} responds to visual cues as well. Hence it is believed that the mosquito compares the flight movement with the ground movement direction visually to stabilise and orient itself towards a certain path \cite{carde1984chemo}. 

By gathering the flight parameters, flight angle and flight speed, it is possible to simplify the data into vector coordinates. Each coordinate states the direction and the magnitude towards the next coordinate. Flight behaviour has been well documented for male moths attracted to pheromones \cite{bau2002antennal, marsh1978analysis, schofield2003flight}. The flight behaviour is gathered in 2-D but ignores the Z component. It is becoming increasingly easier and beneficial to record the flight behaviour in 3-D as well using a complicated arrangement of software and hardware to document mosquitoes \cite{Dekker2963, cooperband2006orientation}, aphids \cite{el2000computer} and fruit-flies \cite{budick2006free}.

\subsubsection{Behaviour within and without an odour plume}
The results gathered from an experiment in \cite{beeuwkes20083} shows how the mosquitoes performed inside and outside an odour plume. A worn sock was used to introduce the odour resulting to a change of flight behaviour of the \textit{Ae. aegypti} mosquito. When the mosquito had no contact with the odour plum it flew in a straight path upwind in contrast to the mosquitoes which flew in the odour plume. The ones that had contact with the odour plume showed \lq longer and more complicated flight paths' as shown in the figure in \cite{beeuwkes20083} (page 141).The experiment also showed that the flight speed and the track angle of the mosquitoes decreased significantly inside the plume than outside. This is also the case in \cite{Dekker2963} but less of a difference in the flight speed. This is quite different from the results of the experiment on \textit{Anopheles gambiae} in \cite{gibson1995behavioural, tirados2006blood} which shows the mosquito using visual cues to orient itself even under low light but \lq possibly less extended than \textit{Ae. aegypti} \rq\cite{beeuwkes20083}. It seems that flight in the darkness is more efficient for \textit{Anopheles gambiae} where the flight speed decreases and the flight path is aimed more towards the source when in contact with the plume. It seems very peculiar that energy is spent in flying a longer path with smaller flight angles when in contact with a plume when a straight path towards the source would be most efficient. It has also been recorded that male moths decreased their flight angles in contact with an odour plume \cite{mafra1994}. However, the flight speed increased in contrast to the \textit{Anopheles gambiae} mosquitoes which decreased their flight in the odour plume. This difference in behaviour in \lq ecology and phylogeny may indicate differences in the underlying processes at the neural level\rq\cite{beeuwkes20083}. 

\cite{beeuwkes20083} also shows that the relative distance to the source of the odour significantly reduced the flight speed of the \textit{Ae. aegypti} mosquito. This was done by dividing the plume into sections and the closest section showed the lowest speed compared to the sections further away. A reason may be attributed to the heat emitted by the source which might cause the mosquito to prepare for a landing. \cite{healy2002landing} found that more \textit{Ae. aegypti} landed on cylinders with temperatures closer to that of a human skin. The plume dimensions and structure were \lq assessed by artificial smoke \rq\cite{beeuwkes20083} where the researchers approximated the odour plume to that of the visible smoke. They smoke increased in turbulence with distance from the source hence increasing the air gaps between the odour plumes. This may cause the mosquito to change the track angle often to ensure it is in the right path towards the source which is more difficult in the sections further from the source hence it speeds up. 

\subsection{Mosquito Visual Structure}
Mosquitoes are either nocturnal or diurnal depending on the species. Diurnal mosquitoes when blood-hunting are subject to light intensities that differ by a factor of 10$^6$, the difference between night and day light. Most invertebrate has a cylindrical ``light guide'' which is a \lq photo-pigment containing region\rq\cite{laughlin1975membranes}. The angle that light is perceived is limited by the critical angle for which the light achieves total internal reflection. \cite{land1997mosquito}. 

For vertebrates the acceptance angle is between $32-38^{\circ}$ \cite{sidman1957structure} in contrast to insects' rhabdoms which have an acceptance angle of $20-25^{\circ}$ if the insect has a lower refractive index \cite{nilsson1989intensity}. Insects which have an apposition type eye (a type of compound eye) do not gain anything \lq by having a wide aperture lens that supplies the rhabdoms with a cone of light wider than $25^{\circ}$\rq \cite{land1997mosquito}. This optical system has a ratio of the lens focus to the diameter of around 2.3 (f-number) which corresponds to that of diurnal Dipteran flies \cite{roebroek1990insect}. Nocturnal mosquitoes, however, have a much larger acceptance angle (about $60^{\circ}$) which corresponds to an f-number of 0.9. This range is too large to be contained in a cone rhabdom hence the rhabdoms are shaped more like a hollow cone where the apex is the focus of the lens \cite{mazokhin1978morphology}. 

\subsubsection{Eye anatomy}
\cite{land1997mosquito} demonstrates geometrically that a conical shape allows light \lq from the outer zones to be trapped \rq. Which increases the received light by a factor of 4-9 times that of a normal cylindrical shape. This method could be compared to the visual system of advanced flies which use a neural superposition system \cite{kirschfeld1967projection, ro1995pupil}. \textit{Anopheles gambiae} is a nocturnal mosquito which is found to be a vector of malaria and other diseases \cite{gillies1988anopheline, white1974anopheles} and are known to blood-feed at night \cite{clements1963physiology}. They have eyes that are relatively small (0.5 mm) but with relative large lenses (24-32 $\mu m$ diameter) \cite{sato1957studies, gray1953properties, mazokhin1978morphology, brammer1970ultrastructure}. Land et al. in \cite{land1997mosquito} found that the mosquito eyes are \lq composed  of six fused outer rhabdomeres and a central rhabdomere, which is presumably a vertical pair\rq which is consistent with the findings in \cite{melamed1975fine, hardie1985functional}. The rhabdom's attachment and arrangement are further described in \cite{land1997mosquito}. 

In essence, the receptors solve the issue of trapping light in a variety of ways \cite{warrant1991strategies} including a conical solution as explained previously. Other solutions are proposed such as barrel-shaped receptors which are able to attain total internal reflection in decapod crustaceans (e.g. shrimp and crabs) \cite{bryceson1983image}. It should be noted that in tipulids , relitives of mosquitoes, rhabdoms of the mosquito function independently \cite{ro1995pupil} which allows the central pair of the pigmented iris to be illuminated when light intensity is higher. At lower light intensities the surrounding rhabdomeres open up and accept light as well which also increases the acceptance angle of the ommatidium (optical units making up the compound eye of an insect) as demonstrated in \cite{land1997mosquito}. However, for the nocturnal \textit{Anopheles gambiae} the rhabdomes are connected at the distal tip which \lq may bean advantage for an animal that is only active in light conditions that vary between dim and dark \rq\cite{land1997mosquito}. 


Mosquito eyes have been described in all their different types in many of Sat$\hat{o}$'s publications and \cite{land1999fundamental} used his work and measurements of ten ommatidia from the centre of the eye to find the focal point of \textit{Anopheles gambiae}, which is the most nocturnal species and \textit{T. brevipalpis} which is a more diurnal species. The results show that both types have a focal point of \lq 42.3 $\mu$m behind the front surface of the cornea\rq. This and the fact that the distal tip of rhabdom in  \textit{Anopheles gambiae} is \lq much closer to the cornea than it is in \textit{T. brevipalpis}\rq\cite{land1999fundamental} suggest that the image perceived by the diurnal species is in focus on the rhabdom tips but the more nocturnal mosquitoes percieve images that are significantly out of focus. A suggestion for this is that due to the relatively wider spherical lenses of the more nocturnal species inducing a large amount of \lq spherical aberration\rq that distort images at a point source, reducing resolution \cite{land1999fundamental}. This is balanced by an increase in sensitivity at dim lighting due to the spherical nature of the distortion by the wide aperture lens. 

\fig{Ch1_iris}{Diagram showing the lens and uncorrected distortion of the nocturnal mosquito \textit{Anopheles gambiae}. Due to the 65$^{\circ}$ cone of light the best image point source is 11.6 $\mu$m towards the lens. This causes a blur circle of 4 $\mu$m in diameter \cite{land1999fundamental}.}{0.45}

It is interesting to note that flies, in contrast to mosquitoes, have two different forms of central rhabdomeres where lies therein four different photoreceptors with different wavelength ranges \cite{lunau2014visual}. This allows them to differentiate between flowers and helps with host finding. 


\subsection{3D Image capture of Mosquito Flight}

Social behaviour of different types of mosquitoes has been studied, however, a major limitation has been \lq in acquiring three-dimensional spatial information of individuals\rq as indicated in \cite{ardekani2012three}. Several research groups tried to automate the data acquisition system however it is still an issue to track flies and smaller insects in three dimensions for a long period of time \cite{grover2008fly, kohlhoff2011ifly, straw2010multi}. 

\subsubsection{Tracking methods}
Tracking usually falls within two categories, two dimensional and three dimensional tracking. For two dimensional systems it is sufficient to use one camera such as in \cite{khan2005mcmc} where ant behaviour has been recorded using a two dimensional tracking approach. For a three dimensional tracking system, multiple views are needed since one view does not provide depth information. Multiple cameras can be used in conjunction to relay tracking moment in a three dimensional scene \cite{hartley2000multiple}. Once the position of the object is found, it can be tracked by algorithms that gathers data from camera filters. Fliters range from the simple Kalman filter (KF) \cite{pistori2010mice}, extended kalman filter (EKF)\cite{grover2008fly, branson2009high} to the Markov-Carlo particle filter \cite{khan2005mcmc}.

\subsubsection{Image reconstruction}
Image reconstruction from multiple views can be achieved by a number of methods. In some studies a two dimensional view is used to reconstruct a three dimensional trajectory by matching \lq two-dimensional fragments temporally\rq\cite{ardekani2012three}. The problem with this approach, however, is matching different tracked two dimensional trajectories and synchronising them over a period of time. A solution has been proposed with regards to tracking hundreds of fruit flies' trajectories using two cameras \cite{wu2011automated}. These produce tracks which are assigned to targets using a linear assignment problem (LAP) which produced three dimensional tracks with the aid of temporal and kinematic cues. A similar approach has been applied in \cite{wu2011automated} where three cameras were used to track a colony of bats. An iterative method was used in this case to find \lq correspondence between views that has the minimum cost\rq\cite{ardekani2012three}. A Kalman filter was used in each view to handle discrepancies and errors by tabulating the two dimensional tracks and the reconstructed three dimensional points.

Other studies took a rather different approach by trying to solve both stereo matching and temporal tracking simultaneously. A solution in \cite{zou2009reconstructing} was proposed where a cost function is defined to differentiate between tracking and view correspondences. The cost function uses two views and integrates the kinetics of the target with regards to the epipolar constraints (target in one camera of the optical centre of the other one). Gibbs sampling was used to reduce the cost function of the targets which the study reported tracking a number of fruit flies in a 200 fps video of around 67.7 frames per second on average. 

A more widely used approach is with the use of multiple views instead of two to reconstruct three dimensional tracks and then use these tracks for temporal tracking. This method has been used to track people in a dense crowd \cite{eshel2008homography} and to track flies and other insects \cite{grover2008fly, straw2010multi}. Depending on the accuracy of the correspondence method, the efficiency may decrease which would lead to an improper three dimensional reconstruction which would alter the track. Grover \textit{et al.} in \cite{grover2008fly} constructed polygon meshes (a number of vertices in a three dimensional space combined to represent a shape) of a fly and they were able to track those meshes using an EKF at real-time. Zou \textit{et al.} in \cite{zou2011recording} used a different approach where a combination of infrared light and visible light in two cameras were used to reproduce an image of a fly as a white image in a dark background. Straw \textit{et al.} in \cite{straw2010multi} were able to estimate the three dimensional points from multiple cameras using a software called ``MOTMOT'' \cite{straw2009motmot} which enables an intersection to be made between multiple camera views. A \lq nearest-neighbour standard filter data association algorithm' is implemented to group separate data points together which represents the tracked animal. In another study, a three dimensional reconstruction was reproduced using one camera and two mirrors \cite{kohlhoff2011ifly}. These mirrors gave two extra views and with the aid of of a virtual representation of a chamber that housed some flies, an image reconstruction was made using geometrical constraints and a \lq steepest descend algorithm\rq.

In \cite{ardekani2012three} a method has been proposed to detect and \lq keep track of multiple flies in a three-dimensional arena for a long period of time\rq. The solution involves the use of multiple cameras which are synchronised and calibrated to track fast moving flies such as \textit{Drosophila}. To track the faster moving flies, the researchers used four cameras running at 30 frames per second (fps) and two additional cameras to detect the \lq visibility of details of the body and wings'  which can be useful when identifying different flight behaviours. This method is an improvement of \cite{kuo2010multi, zhou2004visual} work where the features of the tracked fly, like the colour histogram or shape, is used to keep the tracking system on target. Issues with synchronisation of multiple cameras can be dealt with as seen in \cite{ardekani2012three} where the researchers used a single computer that recorded the frames from the cameras and only captured another frame when it receives the data from the slowest camera. The maximum lag using this method is 1/fps, hence, at 30 fps the lag is approximately 33 ms. Silhouettes can be found from a static camera views using the common background subtraction method \cite{piccardi2004background}. Other methods for silhouette construction have also been such as the Gaussian average method and the mean shift vector techniques like the sequential kernel density approximation \cite{piccardi2004background}. For real time tracking the faster Gaussian average method is more beneficial and it also allows modelling the background at each pixel \cite{ardekani2012three}. 

\section{Virtual Reality Literature Review}

Work in the virtual reality area dates back to the 1960's with Sutherland \cite{sutherland1965ultimate} who wrote the ``Ultimate Display''. Later on Jim Clarke managed to develop a wire-frame virtual reality system to be viewed from ` a head-mounted, BOOM-type display'\cite{cruz1993surround} for his dissertation. Current head-mounted VR devices are commonly either BOOM-type systems \cite{mcdowall1990implementation} or HMD systems \cite{teitel1990eyephone, fisher1987virtual} which use screen motion to represent virtual environments. In 1991 Lipscomb \cite{codella1992interactive} and his team were able to demonstrate a monitor-type VR system in a booth in SIGGRAPH and Deering \cite{deering1992high} demonstrated the ``Virtual Portal'', a system that simulates VR using three wall projection. 

\subsection{What is Virtual Reality?}

Rory Stuart, the author of ``The design of virtual environments'' defines virtual reality as:

`Systems capable of producing an interactive immersive multisensory 3-D synthetic environment; it uses position-tracking and real-time update of visual, auditory, and other displays (e.g., tactile) in response to the user's motions to give the users a sense of being ``in" the environment, and it could be either a single or multi-user system.'\\
\emph{Rory Stuart}\cite{stuart1996design}

Virtual reality simulates real world by adding ``layers'' of depth and lighting cues one gets in the real world. These are:

\begin{enumerate}
    \item  Occlusion (hidden surface)
    \item  Perspective projection
    \item Binocular disparity (stereo glasses)
    \item Motion Parallax (head motion)
    \item Convergence (amount eye rotate toward centre of interest, can be thought of as an optical range finder)
    \item Accommodation (eye focus, i.e. like a single-lens reflex as a range finder)
    \item Atmospheric (fog, etc.)
    \item Lighting and Shadows 
\end{enumerate}

Conventional computer display is able to deliver occlusion, perspective projection, atmospheric and lighting/shadows visual cues. VR enables 3,4 and 5 but not accommodation since everything appears in focus even objects that are very close to the ``virtual eye'' which should naturally be out of focus. It would be interesting to have a headset display which was able to do that, maybe with a small camera inside the headset which records eye movement and depending on the location of the eye it is then able to show objects at different distances from the user to be in and out of focus. Granted that would ultimately induce headaches since the lag associated with such a system would slower than the natural human response. 

To attain virtual reality effect the system in use must be must be able to deliver high quality images at intervals that would feel natural to the eye. The requirements for virtual reality or `real-time performance' \cite{bryson1996virtual} is:
\begin{itemize}
    \item The feedback sent to the user, as the user is updating the input continuously, must be less than 0.1 seconds. This allows for a more accurate manipulation of the environment \cite{sheridan1974man}. 
    \item The graphic animation of the environment must be at least 10 frames per second \cite{bryson1996virtual}. This is the minimum amount of frame rate updates needed to give a sense of three dimensional presence, however, it should be noted that the frame rate is clearly visible at such a low frequency of frame updates. 
    \item The environment must contain objects with low enough fidelity, or vertices, to increase performance but is adequate enough for the user to understand what the object is.
\end{itemize}

\subsection{Virtual Environment: Operational Explanations and Definitions}

Some terms and concepts are defined in this section that are used in industry standard three dimensional visualisation software.

\subsubsection{Vertices, polygons and meshes}
A mesh can be thought of as a bundle of vertex or vertices that represent an object where they form the ``surface'' of the object, as in the object is usually hollow inside since it would not normally be viewed by the user. Take a slab a wood as an example. At its simplest for the slab could be constructed by four vertices where the four vertices are the corners of the slab of wood. This is a good method of representing ``low-poly'' objects where a polygon is one face of the slab which is just one square. Low-poly models are usually used to present objects at the initial design phase, mainly for getting rough ideas. For software that compute physical interaction like load on a beam, polygons are used to house the mathematical approximations which work together resemble the real world effect. As the polygon count increases so does the accuracy of the object to represent the real world object.

\subsubsection{Mesh density}
Polygons are, in most cases, a set of four or three vertices which connect to form a square or a triangle. These are then connected together to form an object and a more complex object would need more polygons to represent the object accurately. This is not dissimilar to how a layer of graphite is constructed using hexagonal ``polygons''. As the number of polygons increases so does the ability to construct bumps and deformities that are more natural, however, this also increases the mesh density. Rendering is the act of calculating all the different visual as well as intrinsic effects that make up the three dimensional visualisation and as the mesh density increases so does the rendering time. Rendering takes into account everything from visuals such as lighting, mesh colour mapping, shadows, and geometric shape to the more intrinsic functions like physical properties, structural integrity, interaction with realistic ``physics'' and so on.  

\subsubsection{Particles and physics}
Particles are used to represent effects such as wind flow and flame effects. These particles are encoded to act in a certain way with themselves and with other objects such that they behave more realistically. The difference between particles and meshes is that particles are usually coded to act in such a behaviour as to emulate a real world phenomenon and thus it can be studied in abnormal situations. Meshes, on the other hand, are more normally used to represent an object with physical properties that effect the particles flowing either around or close enough to interact with it.

Physics in the three dimensional world is where meshes and the environment are encoded in such a way to emulate the real world. Gravity, collision detection and inertia are some forms of the physics used in virtual environments. It should be noted that the accuracy of these physics are wholly dependent upon the method of encoding and approximation used when doing so, as such, different software have different means of interacting with the physics. Collision detection is explained in Youn and Wohn's work where they describe it as a method which `exploits a hierarchical object representation to facilitate the detection of colliding objects.' \cite{youn1993realtime}. Objects with this type of physics enabled contain segments which interact with other segments individually and as a whole. The methodology of the algorithm is described in \cite{jayaram1997virtual}, and the basic theory behind how the algorithm computes is by looking for the most probable collision of vertices and determine and then determine if they actually collide or not. It is also interesting to note Cohen \textit{et al.}'s work in \cite{cohen1994interactive} where they propose a method that does not compute any assumptions about time-dependant trajectories but instead computes exact collision detection. This is done by using a two-level hierarchical approach that looks at the exact points of contact in the virtual environment.


\subsection{Demands of real-Time Visualisation}
In two dimensional visualisation, usually involves one data set containing a value at each point, is it sufficient to for it to be presented in a picture. Where ``picture'' is a two dimensional graphic representing data at a specific x-y coordinate. However, for more complex engineering and data visualisation techniques more parameters are needed to represent the given data. Time is needed for transient systems as well as one more dimension, the z-plane, to represent three dimensional problems. These additional dimensions make it possible to show vectors in three axis, to compute forces, dimensions and trajectories of particles and display them in a more user friendly way. Real-time interactive data can be used in such cases however, the interactive aspect is heavily reliant on the complexity of the data. The more complex the data is, the more graphically demanding it can get, which would lead to a drop in frame rate. In worse cases the frame rate would literally take minutes or even hours to update. 

Consider a computational fluid dynamic model (CFD) to be visualised in VR. CFD simulations typically contain 5 parameters and these are energy and pressure as well as the three components of velocity. These data points are usually very large containing millions of points per simulation time step for hundreds of time steps. For the system to be realistic, these data points must contain more and more information and hence making them drastically larger.  For CFD in particular, the visualisation becomes more complicated due to the data which is `provided either on multiple overlapping stretched computational grids or on unstructured grids'\cite{bryson1996virtual}. Both of these cases must present the data explicitly hence further increasing the data size. An example for the scale of the system is NASA's Ames Research centre who work with data sets exceeding 200 gigabytes \cite{bryson1996virtual}. Another example of the scale of CFD modelling consider the data set of a hovering harrier jump-jet aircraft \cite{smith1991numerical}. The numerical model of the system was presented such that each data set contained 2.8 million points, each point is distributed among 18 overlapping grids. The data size for a single time-step is now 56 megabytes without considering the 42-megabyte data that provide the positions.

\subsubsection{Computation demands of real-time interactive visualisation}
Every technique of data visualisation introduces case specific computation demands on the system. A visualisation of an environment that is only colour mapping of existing geometry, e.g. Abaqus\textregistered{} simulation of a beam model under constant stress, requires little computational power. However, visualisation of a system using particle integration where accuracy of result is a major factor requires much more processing time and is very dependant on the amount of particles being processed. Even in isosurface computation used in Abaqus\textregistered\space can be computationally intensive depending on the data set and the number of points needed for simulation. The idea of a  data point, for systems like stress simulation at element level,  is basically an element which represent a mathematical matrix that defines the characteristic of such systems under stress conditions like compression. The smaller the element the more accurate the system is. This is due to the area the element is representing being smaller, hence more realistic. Some examples of reducing computational demands are outlined in the following paragraphs.


\subsubsection{Computer architecture}

Computer architecture come in three widely popular formats; scalar, vector and parallel, each of which approaches data management differently. Scalar architecture makes the least amount of ``assumptions'' on the computation being performed, hence, it is the most versatile. However, assumptions are needed to help speed up the computation process which translates to the scalar architecture being the slowest but more realistic. Vector computation is based on the assumption that in each computation step there are n-amount of sequential steps thereby allowing these steps to be loaded on the processor. This holds true unless a subroutine calls and memory access are needed in the computation step. Lastly, parallel architecture is used when a large amount of scalar processes are needed and work best in situations where a large amount of small computations are required. Parallel architecture is least used in visualisation due to the computation needed for visualisation require an iterative approach.


There are many ways to solve a computation request but there is a trade off for such systems and that is between accuracy and performance time. Faster systems are generally less accurate due to assumptions being made in the computation steps. An example is that using a third order system instead of a seventh-order approximation and so on. Systems are usually aimed to perform faster than more accurate but care should be taken such that the present model is not too far from real system. The balance between accuracy and speed is context driven for example when simulating an aircraft it is critical to represent the data as accurately as possible hence the simulation could possibly take days. A method could be placed where the weight between accuracy and speed could be updated depending on the case automatically or depending on the user's need.
\subsubsection{Graphics and three dimensional display}
Scientific visualisation can be very demanding for the system due to the accuracy needed to represent the model. The model in the virtual environment must be able to represent the data as accurately as possible, i.e. high detailed meshes with full resolution texture and colour mapping. These high resolution maps have to be re-rendered for every time step making it virtually impossible to display real-time application in high resolution with user input. The program cannot ``predict'' the user inputs and pre-render the image or data flow so it must wait for the input and then process it. However, in situations where user input is not needed it is more plausible to use high resolution mapping since the software can do all the processing before hand. Although, in some situations, the process can be rendered before-hand and from there on the user could view the visualisation without the capability of interacting with the data but only perceived it in different formats. Take for example wind flow over an aircraft's wings as it changes altitude. A technique to make high resolution visualisation would be to render all the particles that represent airflow for the fraction of the total time and then loop it so that it seems continues. This technique cannot be used in this situation since the airflow change with the aircraft's pitch so now the system has to render the whole process from start to finish which is very demanding. If the system allows for user control where the user is able to change the pitch then one of two methods could be used to help reduce system computation demand. One is to pre-render all situations the user might input and hence make it so the data is ``hidden unless'' the user chooses to activate it. The other method is to reduce accuracy, thereby decreasing system simulation time, by reducing particle number and mesh density. 


\subsection{Application of virtual reality}

\subsubsection{Virtual reality in the sciences}

Application of virtual reality in the scientific visualisation field is now plausible due to the possibility of custom made three dimensional environments and the ability to mimic real life with the use of complex computation models. Virtual wind tunnels \cite{bryson1992distributed, bryson1991virtual},  virtual spacetime \cite{bryson1992virtual}, molecular modelling \cite{brooks1990project}, display at microscopic levels \cite{taylor1993nanomanipulator} and medical visualisation systems \cite{bajura1992merging} are example such applications.

Perhaps the the most obvious route to use virtual reality is for three dimensional design and manufacturing process. \cite{jayaram1997virtual} states that three dimensional computer aided design will provide `a means to envision, refine, and develop a product or process with significant cost and time savings'. The paper introduces the idea of ``Design by Manufacture'' in a virtual environment where accurate representations of the manufacturing process is coded in such a way that the designer is able to design the system within the boundaries of `machine tools, assembly tools. transfer lines. etc.'. This is a very interesting approach to manufacture since it allows for the machines to be constructed and tuned in a virtual environment so that the final product could be presented in all the different iterations in a time and cost saving manner. 

%%look at this part further

In the medical field, impairment in the upper Limb is very common following neurological injuries \cite{murphy2006three}. Both arms and hand functions are affected after a spinal cord injury, by varying degrees, especially in tetraplegia \cite{harvey2001hand}.  Due to the importance of the upper limbs in ones daily life, an ailment would cause a profound effect on the quality of life of the individual. Kinematic analysis in tetrapalegic can produce data of the approach to motor movements in affected individuals \cite{cacho2011upper} which give information on the individual's actual capabilities \cite{murphy2006three}. Three dimensional motion capture turns out to be a very useful way to quantitatively asses upper limb movements \cite{de2010kinematic}. When virtual reality is used in for said assessment it provides a useful environment to develop human performance testing and training \cite{lee2003virtual}. VR provides a method to replicate daily motions associated with specific environments which allows the evaluation of the skills needed to interact with such environments \cite{dimbwadyo2013clinical}. This eliminates risks associated by adapting exercises and machines to each individual's needs and instead adapts a virtual environment which can be easily manipulated \cite{lee2003virtual}. It has been recorded in \cite{dimbwadyo2016activities} a significant improvement between participants who received virtual training for thirty minutes, three times a week, compared to participants which received conventional rehabilitation everyday. The researchers used Toyra\textregistered, a system capable of displaying a virtual self with real-time motion by using a set of sensors which provided kinematic data. The data is then assessed using an agility metric which considers an agile movement being both fast and precise \cite{trincado2014kinematic}. The results of their work show that the VR system `could be a good estimator of functionality, mainly in parameters related to shoulder movements'\cite{dimbwadyo2016activities}. 

Zhang \textit{et al.} demonstrates a method for using virtual reality as a simulator for arthroscopic surgery. His idea is to use a manipulator design which possesses 4 degree of freedom that are pitch, yaw, translation along the handle and rotation of the handle. The first three degrees of freedom are used to help navigate in the three dimensional environment while the final degree of freedom represent the orientation of the tip of the mechanism. After a direct and inverse kinematic analysis, the researchers designed a control system which used the kinematic analysis as boundaries and the end result was a functioning manipulator that operated the same way a surgeon operated his tools. A VR system which is capable of displaying cosmic formations has been implemented at the national centre for supercomputing applications \cite{song1993cosmic}. Additionally, the university of Illinois has also implemented techniques for scientific visualisation \cite{cruz1993surround, cruz1993scientists}.

\subsubsection{Virtual reality in training}
Virtual reality has been shown to aid in training processes multiple times in a variety of fields. In \cite{garcia2016virtual}, Garcia \textit{et al.}, demonstrate an application of VR in training for high voltage power line maintenance where a virtual environment is made to mimic a voltage distribution steel tower. The workforce were able to study the method and approaches to resolving issues like insulator string substitution, lead wire repair and replacement of a damaged structure in a safe environment. Research has also been done to teach fire-safety skills and escape techniques \cite{smith2009using}. Virtual reality has also been used for periodontal training  and the conclusion of one relevant paper states that participants of the study where able to demonstrate `the scientific contribution and usefulness of the simulator as a vital part of the curriculum of the Department of Periodontics' \cite{luciano2009haptics}.

\subsection{Use of 3D and Virtual Environments for Animal Behaviour Research}

Virtual reality can be used as a platform to study animal behaviour and their visual systems due to the flexibility of the platform enabling custom models to be used. Tethered insects' behaviour have been studied \cite{gray2002method} and free roaming rats \cite{o1971hippocampus, lee2009head}, both in virtual environments. This is done by visual feed that emulates the animal's natural environment so when the animal moves the environment updates to act as if the animal is moving in the environment. An example of such application is presented in \cite{takalo2012fast} where the researchers constructed a rather clever system which allows a mosquito to walk on top of a track-ball inside a sphere. As the trackball moves, the projector mounted on the roof of the sphere updates the visual feed to accompany the movement. Their approach, although clever in design, distorted the environment due to the curvature of the sphere and other factors such as geometrical mapping of the image. This type of virtual projection must take into account the curvature of the specific sphere as well as the recording method should be in such a way to make sure the extreme angles are displayed naturally. Granted that the display is constructed for an insect and not a human, and the idea of making a virtual headset for a cockroach is both humorous and warrant further research, care should be taken that the data collected is not too far from a more natural approach. Not much else has been done in studying animal behaviour using virtual reality as a platform. Virtual reality, as it stands, is a fairly new concept, one that requires a non-familiar approach for data visualisation. This unfamiliarity could cause researchers to stay away from VR in the sciences but it is the hope of this thesis to show the strengths of VR in realistic data visualisation.

\section{How this Project Builds upon Existing Work}

The behaviour of mosquitoes have been thoroughly researched and understood. However, the field of scientific visualisation of animal behaviour, especially using virtual reality, is hardly studied. A reason for this is the relatively new idea of virtual reality is only just becoming commercially available. The CAVE projects, although advanced for its time, lend no convenient method of interactiveness making it virtually impossible to shift through data. Emulation of an immersive environment by use of curved surfaces are not easily done and usually cause distortions \cite{takalo2012fast}. 

This project aims to use more modern means of using a virtual environment to study mosquito behaviour in a whole new dimension making it possible to not only be standing next to the virtual mosquito as it flies but also makes it possible to become the mosquito and look at the surrounding in this whole new perspective which has not been done before as far as insect flight behaviour goes. 

Some virtual environments allow for the use of physics such as acceleration, weight and inertia which makes it possible to emulate a mosquito's flight more naturally. This can improve the accuracy of representation in works such as \cite{Dekker2963} and \cite{beeuwkes20083}. By adding this new dimension in analysing flight behaviour, a more realistic representation of flight behaviour can be modelled and presented.

\section{Material and Methods}

There are a few approaches to displaying the visuals in VR and it is very dependant on the software and hardware in use. A lot of different software are capable of rendering into VR and it all comes down to preference. 

\subsection{Software and Hardware}

Autodesk's Maya\textregistered and other 3D computer graphics software like 3D-Max and Blender are industry standard software capable of displaying in VR. They are best used for animations and modelling, however, due to the complexity of some animations these software are equipped with the ability to convert python scripts into animation data. For example a model of the mosquito could be made from one of these software and then a python code could be used to control its positional and temporal data. However using a gaming software like Unity\textregistered{} or Unreal Engine\textregistered{} is more effective for a variety of reasons. Firstly, they accept java and C language and are made in such a way that anyone could use it even with limited knowledge of programming. Secondly, they have intrinsic mathematical code that compute physics which can be used to apply gravity, momentum, mass and so on to any object. For this project Unity\textregistered{} will be used.

For the hardware it would be easier to use a phone as the platform since they are relatively cheap, compared to the more advanced VR hardware like the Oculus Rift, and widely available. Almost all phones are capable of displaying in VR by using Google's cardboard or Daydream\textregistered{} which is an updated version of the cardboard and allows the use of a touch interface using a blue-tooth controller. 

Hence using a combination of a gaming platform to render in VR and a Daydream\textregistered{} would satisfy the requirements for both VR display and a touch interface.

\subsection{Method}

The data gathered from my supervisor, D.Towers, and his team are displayed in (x,y,z,t) so each time step contains values for the three dimensions. The first step would be to convert these numbers into a language that the software would understand as 3D coordinates with time. Java could be used to convert the text based (x,y,z,t) into software coordinates. 

The second step would be to model the mosquito and make it follow the coordinates. A simple method could be by making a target appear in the coordinate of the mosquito at the moment $t=t$ and make it disappear when $t<0$ or $t>0$. A code could then be written so that if the mosquito would always fly towards the target. This, although simple in concept, would provide a way to use the physics of the environment to influence the mosquitoes movement making it more realistic. An issue could be that the target appears and disappears before the mosquito has the chance to fly towards the target, so careful tuning of the velocity, gravity, acceleration and mass parameters should be exercised.

Once the software displays the mosquito flight properly an interface should be made to switch between the views and between the flight data. Google's Daydream\textregistered{} view comes with its own touch interface making it easy to configure the touch interaction. A system should be placed where a touch would change the view and this could be done by adding something called a gaze view. The gaze view acts like a mouse and it is the centre focus of the VR system, i.e. a reticle could coded to stay in the middle of the view and interact with the software when it is hovered on a specific object and the button is clicked. A simple example to change view would be to ask the user to look at the red cube and click the button to change to mosquito view. This method can be extended to include pause, play, change time and so on.

\subsubsection{Making a model for the environment and touch display}

At this point the mesh of the bednet and the host have to be made to give a perspective of the mosquitoes flight path. One way to do that is to use Blender which is an open source free modelling software. Both models can be made in Blender and exported to Unity, however, some elements may not be retained when exporting like the colour mapping and the mesh density, so further work may have to be done after exporting. 

A display should also be made and coded so that it acts as an interactive overlay. The code would position it at the corner of the screen when in mosquito view and at the side when in observer view. 

\begin{landscape}
\subsection{Time Table}
\fig{Timetable}{Time table for the first two months of work.}{0.7}
\fig{Timetable2}{Time table for the Third and fourth months. After this point all work would be related to tuning the code and writing the dissertation.}{0.7}
\end{landscape}

%\fig{TimeTable1}{Table of time}{0.085}
%\fig{TimeTable2}{Table of time}{0.085}
